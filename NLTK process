import re
from nltk.tokenize import word_tokenize
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
f=open('tiny_text.txt','r')
re=f.read()
tok=word_tokenize(re)
print(tok)
tag=nltk.pos_tag(tok)
print(tag)
stop = set(stopwords.words('english')) 
st=stopwords(tok)
print(st)
str=PorterStemmer()
for i in tok:
  print(i,str.stem(i))
print("_________________________________________________________________________")
print("after lemmatizing the words")
for il in tok:
    print(il,WordNetLemmatizer().lemmatize(il))

stop = set(stopwords.words('english')) 
print(stop)
newt=[]      
for wor in tok:
    if wor not in stop:
       newt.append(wor)  
print(newt)
